#nullable enable
#pragma warning disable IDE0063 // Use simple 'using' statement
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace DatabaseValueSearcher
{
    public class ExportService
    {
        private readonly CacheManager cacheManager;

        public ExportService(CacheManager cacheManager)
        {
            this.cacheManager = cacheManager;
        }

        /// <summary>
        /// Shows export menu and handles table selection for export
        /// </summary>
        public async Task ExportCachedTableMenu(SearchSession? currentSession, Func<SearchSession, int, Task<DataPage?>> loadOrFetchPageFunc)
        {
            Console.WriteLine();

            if (currentSession?.CachedData != null)
            {
                Console.Write("Export current table cache? [Y/n]: ");
                string response = Console.ReadLine()?.Trim() ?? "";

                if (string.IsNullOrEmpty(response) || response.Equals("y", StringComparison.OrdinalIgnoreCase))
                {
                    await ExportTableCacheToSQL(currentSession, loadOrFetchPageFunc);
                    return;
                }
            }

            // Show all cached tables for export
            var cachedTables = cacheManager.GetAllCachedTables();

            if (!cachedTables.Any())
            {
                DisplayMessages.WriteWarning("No cached tables found to export.");
                return;
            }

            Console.WriteLine("Select table to export:");
            for (int i = 0; i < cachedTables.Count; i++)
            {
                var table = cachedTables[i];
                var completeness = table.IsComplete ? "Complete" : "Partial";
                Console.WriteLine($"  {i + 1}. {table.Environment}.{table.Database}.{table.TableName} ({table.TotalRows:N0} rows, {completeness})");
            }

            Console.Write($"Select table (1-{cachedTables.Count}) [back]: ");
            string input = Console.ReadLine()?.Trim() ?? "";

            if (input.Equals("back", StringComparison.OrdinalIgnoreCase) || string.IsNullOrEmpty(input))
                return;

            if (int.TryParse(input, out int selection) && selection >= 1 && selection <= cachedTables.Count)
            {
                var selectedTable = cachedTables[selection - 1];

                // Create temporary session for export
                var tempSession = new SearchSession
                {
                    Environment = selectedTable.Environment,
                    Database = selectedTable.Database,
                    TableName = selectedTable.TableName,
                    CachedData = cacheManager.LoadMetadata(selectedTable.CacheKey)
                };

                await ExportTableCacheToSQL(tempSession, loadOrFetchPageFunc);
            }
            else
            {
                DisplayMessages.WriteError("Invalid selection.");
            }
        }

        /// <summary>
        /// Exports cached table data to SQL file with CREATE and INSERT statements
        /// </summary>
        public async Task ExportTableCacheToSQL(SearchSession session, Func<SearchSession, int, Task<DataPage?>> loadOrFetchPageFunc)
        {
            if (session.CachedData == null)
            {
                DisplayMessages.WriteError("No cached table data available to export.");
                return;
            }

            DisplayMessages.WriteInfo("Exporting cached table data to SQL file...");

            try
            {
                var metadata = session.CachedData;

                // Calculate total pages
                var totalPages = (int)Math.Ceiling((double)metadata.TotalRows / metadata.PageSize);

                // Create export filename
                var timestamp = DateTime.Now.ToString("yyyyMMdd_HHmmss");
                var filename = $"{session.TableName}_Export_{timestamp}.sql";
                var exportPath = Path.Combine(Environment.CurrentDirectory, "Exports");

                if (!Directory.Exists(exportPath))
                {
                    Directory.CreateDirectory(exportPath);
                }

                var fullPath = Path.Combine(exportPath, filename);

                using var writer = new StreamWriter(fullPath, false, Encoding.UTF8);

                // Write header
                await writer.WriteLineAsync("-- SQL Export Generated by Database Value Searcher");
                await writer.WriteLineAsync($"-- Source: {session.Environment}.{session.Database}.{session.TableName}");
                await writer.WriteLineAsync($"-- Generated: {DateTime.Now:yyyy-MM-dd HH:mm:ss}");
                await writer.WriteLineAsync($"-- Total Rows: {metadata.TotalRows:N0}");
                await writer.WriteLineAsync();

                // Write table creation script
                await WriteTableCreateScript(writer, metadata);
                await writer.WriteLineAsync();

                var insertedRows = 0;
                var batchSize = 1000; // Insert in batches
                var currentBatch = new List<Dictionary<string, object?>>();

                DisplayMessages.WriteInfo($"Processing {totalPages} pages for export...");

                // Process each page
                for (int pageNum = 1; pageNum <= totalPages; pageNum++)
                {
                    var page = await loadOrFetchPageFunc(session, pageNum);
                    if (page?.Rows == null || !page.Rows.Any()) continue;

                    foreach (var row in page.Rows)
                    {
                        currentBatch.Add(row);

                        if (currentBatch.Count >= batchSize)
                        {
                            await WriteInsertBatch(writer, session.TableName, metadata, currentBatch);
                            insertedRows += currentBatch.Count;
                            currentBatch.Clear();
                        }
                    }

                    // Show progress
                    if (totalPages > 10 && pageNum % Math.Max(1, totalPages / 10) == 0)
                    {
                        var progress = (double)pageNum / totalPages * 100;
                        DisplayMessages.WriteInfo($"Export Progress: {progress:F1}% ({insertedRows:N0} rows exported)");
                    }
                }

                // Write remaining batch
                if (currentBatch.Any())
                {
                    await WriteInsertBatch(writer, session.TableName, metadata, currentBatch);
                    insertedRows += currentBatch.Count;
                }

                await writer.WriteLineAsync();
                await writer.WriteLineAsync($"-- Export completed: {insertedRows:N0} rows exported");

                DisplayMessages.WriteSuccess($"Export completed successfully!");
                DisplayMessages.WriteInfo($"File: {fullPath}");
                DisplayMessages.WriteInfo($"Rows exported: {insertedRows:N0}");
            }
            catch (Exception ex)
            {
                DisplayMessages.WriteError($"Export failed: {ex.Message}");
            }
        }

        /// <summary>
        /// Writes CREATE TABLE script based on cached metadata
        /// </summary>
        public async Task WriteTableCreateScript(StreamWriter writer, CachedTableData metadata)
        {
            await writer.WriteLineAsync($"-- Create table script for {metadata.TableName}");
            await writer.WriteLineAsync($"IF NOT EXISTS (SELECT * FROM sys.objects WHERE object_id = OBJECT_ID(N'[{metadata.TableName}]') AND type in (N'U'))");
            await writer.WriteLineAsync("BEGIN");
            await writer.WriteLineAsync($"    CREATE TABLE [{metadata.TableName}] (");

            var columnDefinitions = new List<string>();

            foreach (var column in metadata.Columns)
            {
                var lengthPart = column.MaxLength > 0 ? $"({column.MaxLength})" :
                                column.MaxLength == -1 ? "(MAX)" : "";
                var nullPart = column.IsNullable ? "NULL" : "NOT NULL";

                columnDefinitions.Add($"        [{column.Name}] {column.DataType.ToUpper()}{lengthPart} {nullPart}");
            }

            await writer.WriteLineAsync(string.Join(",\n", columnDefinitions));

            if (metadata.PrimaryKeys.Any())
            {
                await writer.WriteLineAsync(",");
                var pkColumns = string.Join(", ", metadata.PrimaryKeys.Select(pk => $"[{pk}]"));
                await writer.WriteLineAsync($"        CONSTRAINT [PK_{metadata.TableName}] PRIMARY KEY CLUSTERED ({pkColumns})");
            }

            await writer.WriteLineAsync("    );");
            await writer.WriteLineAsync("END");
        }

        /// <summary>
        /// Writes batch INSERT statements for a group of rows
        /// </summary>
        public async Task WriteInsertBatch(StreamWriter writer, string tableName, CachedTableData metadata, List<Dictionary<string, object?>> batch)
        {
            if (!batch.Any()) return;

            var allColumns = new List<string>(metadata.Columns.Select(c => c.Name));
            allColumns.AddRange(metadata.PrimaryKeys.Where(pk => !allColumns.Contains(pk)));

            await writer.WriteLineAsync($"INSERT INTO [{tableName}] ([{string.Join("], [", allColumns)}])");
            await writer.WriteLineAsync("VALUES");

            var valueRows = new List<string>();

            foreach (var row in batch)
            {
                var values = new List<string>();

                foreach (var column in allColumns)
                {
                    var value = row.GetValueOrDefault(column);
                    values.Add(FormatSQLValue(value));
                }

                valueRows.Add($"    ({string.Join(", ", values)})");
            }

            await writer.WriteLineAsync(string.Join(",\n", valueRows));
            await writer.WriteLineAsync(";");
            await writer.WriteLineAsync();
        }

        /// <summary>
        /// Formats a value for SQL INSERT statement with proper escaping
        /// </summary>
        public string FormatSQLValue(object? value)
        {
            if (value == null || value == DBNull.Value)
                return "NULL";

            return value switch
            {
                string s => $"'{s.Replace("'", "''")}'",
                DateTime dt => $"'{dt:yyyy-MM-dd HH:mm:ss.fff}'",
                DateTimeOffset dto => $"'{dto:yyyy-MM-dd HH:mm:ss.fff zzz}'",
                TimeSpan ts => $"'{ts}'",
                bool b => b ? "1" : "0",
                byte[] bytes => $"0x{Convert.ToHexString(bytes)}",
                Guid g => $"'{g}'",
                decimal d => d.ToString(System.Globalization.CultureInfo.InvariantCulture),
                double d => d.ToString(System.Globalization.CultureInfo.InvariantCulture),
                float f => f.ToString(System.Globalization.CultureInfo.InvariantCulture),
                _ => value.ToString()?.Replace("'", "''") ?? "NULL"
            };
        }

        /// <summary>
        /// Gets export statistics for a cached table
        /// </summary>
        public ExportStatistics GetExportStatistics(SearchSession session)
        {
            var stats = new ExportStatistics();

            if (session.CachedData == null)
            {
                stats.IsExportable = false;
                stats.ErrorMessage = "No cached data available";
                return stats;
            }

            var metadata = session.CachedData;
            var cacheKey = cacheManager.GetCacheKey(session.Environment, session.Database, session.TableName);
            var cacheStats = cacheManager.GetCacheStatistics(cacheKey);

            stats.IsExportable = cacheStats.HasMetadata && cacheStats.CachedPages > 0;
            stats.TableName = session.TableName;
            stats.TotalRows = metadata.TotalRows;
            stats.TotalPages = (int)Math.Ceiling((double)metadata.TotalRows / metadata.PageSize);
            stats.CachedPages = cacheStats.CachedPages;
            stats.EstimatedFileSize = EstimateExportFileSize(metadata, cacheStats);
            stats.IsComplete = cacheStats.CachedPages == stats.TotalPages;

            if (!stats.IsExportable)
            {
                stats.ErrorMessage = "No cached pages available for export";
            }

            return stats;
        }

        /// <summary>
        /// Estimates the size of the exported SQL file
        /// </summary>
        private long EstimateExportFileSize(CachedTableData metadata, CacheStatistics cacheStats)
        {
            // Rough estimation based on:
            // - Average row size from cache statistics
            // - SQL overhead (INSERT statements, CREATE TABLE, etc.)

            if (cacheStats.CachedPages == 0 || metadata.TotalRows == 0)
                return 0;

            var avgRowSize = cacheStats.TotalCacheSize / Math.Max(1, metadata.TotalRows);
            var sqlOverheadPerRow = 50; // Estimated overhead for INSERT statement per row
            var headerSize = 1024; // CREATE TABLE and headers

            return (avgRowSize + sqlOverheadPerRow) * metadata.TotalRows + headerSize;
        }
    }

    /// <summary>
    /// Statistics and information about an export operation
    /// </summary>
    public class ExportStatistics
    {
        public bool IsExportable { get; set; }
        public string TableName { get; set; } = string.Empty;
        public long TotalRows { get; set; }
        public int TotalPages { get; set; }
        public int CachedPages { get; set; }
        public long EstimatedFileSize { get; set; }
        public bool IsComplete { get; set; }
        public string ErrorMessage { get; set; } = string.Empty;

        public string EstimatedFileSizeDisplay => EstimatedFileSize < 1024 * 1024
            ? $"{EstimatedFileSize / 1024:N0} KB"
            : $"{EstimatedFileSize / 1024 / 1024:N1} MB";

        public double CompletionPercentage => TotalPages > 0 ? (double)CachedPages / TotalPages * 100 : 0;
    }
}